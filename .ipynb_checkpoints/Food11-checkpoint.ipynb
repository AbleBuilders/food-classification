{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1xkY298nqsM4"
   },
   "source": [
    "# TASK #1: PROJECT OVERVIEW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 118
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 33584,
     "status": "ok",
     "timestamp": 1592528400055,
     "user": {
      "displayName": "Kukeshajanth Kodeswaran",
      "photoUrl": "",
      "userId": "09269573466384281285"
     },
     "user_tz": 240
    },
    "id": "xEzvoBt8vEvH",
    "outputId": "d81bac26-7ff7-4f2f-b7ea-84c7463d36e6"
   },
   "outputs": [],
   "source": [
    "#mount the drive\n",
    "\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QFLf1y4xqzGl"
   },
   "source": [
    "# TASK #2: IMPORT LIBRARIES/DATASETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 15124,
     "status": "ok",
     "timestamp": 1592528401604,
     "user": {
      "displayName": "Kukeshajanth Kodeswaran",
      "photoUrl": "",
      "userId": "09269573466384281285"
     },
     "user_tz": 240
    },
    "id": "lf_7805PvGgZ",
    "outputId": "56b1cc12-8399-44ad-f68d-937a6e46ad24"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-32e645b011f5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;31m# from tensorflow.keras.applications.resnet18 import ResNet18\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapplications\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mMobileNet\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapplications\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minception_resnet_v2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mInceptionResNetV2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'keras'"
     ]
    }
   ],
   "source": [
    "#import the necessary packages\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "# from tensorflow import keras\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL\n",
    "import seaborn as sns\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "# from tensorflow.keras.applications.resnet18 import ResNet18\n",
    "\n",
    "from keras.applications import MobileNet\n",
    "from tensorflow.keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.initializers import glorot_uniform\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from IPython.display import display\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint, LearningRateScheduler\n",
    "from jupyterthemes import jtplot\n",
    "jtplot.style(theme='monokai', context='notebook', ticks=True, grid=False) \n",
    "# setting the style of the notebook to be monokai theme  \n",
    "# this line of code is important to ensure that we are able to see the x and y axes clearly\n",
    "# If you don't run this code line, you will notice that the xlabel and ylabel on any plot is black on black and it will be hard to see them. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1462,
     "status": "ok",
     "timestamp": 1592528403092,
     "user": {
      "displayName": "Kukeshajanth Kodeswaran",
      "photoUrl": "",
      "userId": "09269573466384281285"
     },
     "user_tz": 240
    },
    "id": "GUmPRk_NvrXz",
    "outputId": "5fec6b57-9bc1-494f-f1b8-96dd13280979"
   },
   "outputs": [],
   "source": [
    "%cd /content/drive/My Drive/food11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WiV9-QvCrA3I"
   },
   "source": [
    "# TASK #3: DATA EXPLORATION AND DATA VISUALIZATION:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 66
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 53702,
     "status": "ok",
     "timestamp": 1592528455354,
     "user": {
      "displayName": "Kukeshajanth Kodeswaran",
      "photoUrl": "",
      "userId": "09269573466384281285"
     },
     "user_tz": 240
    },
    "id": "A_EUHCz30v79",
    "outputId": "20d13881-60fe-4b4f-9578-ec9b5da0dbda"
   },
   "outputs": [],
   "source": [
    "# Check the number of images in training, validation and test dataset\n",
    "\n",
    "train = []\n",
    "valid = []\n",
    "test = []\n",
    "\n",
    "#os.listdir returns the list of files in the folder, in this case image class names\n",
    "for i in os.listdir('./training'):\n",
    "  train_class = os.listdir(os.path.join('training',i))\n",
    "  train.extend(train_class)\n",
    "  valid_class = os.listdir(os.path.join('validation',i))\n",
    "  valid.extend(valid_class)\n",
    "  test_class = os.listdir(os.path.join('evaluation',i))\n",
    "  test.extend(test_class)\n",
    "\n",
    "print('Number of train images : {} \\nNumber of validation images : {} \\nNumber of test images : {}'.format(len(train),len(valid),len(test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 54587,
     "status": "ok",
     "timestamp": 1592518678792,
     "user": {
      "displayName": "Kukeshajanth Kodeswaran",
      "photoUrl": "",
      "userId": "09269573466384281285"
     },
     "user_tz": 240
    },
    "id": "8bw_N3GC2GPi",
    "outputId": "53424df7-fa4a-4745-a83f-06cfa1bfee2d"
   },
   "outputs": [],
   "source": [
    "# Visualize the images in the dataset\n",
    "\n",
    "fig, axs = plt.subplots(11,5, figsize=(32,32))\n",
    "count = 0\n",
    "for i in os.listdir('./training'):\n",
    "  # get the list of images in the particualr class\n",
    "  train_class = os.listdir(os.path.join('training',i))\n",
    "  #plot 5 images per class\n",
    "  for j in range(5):\n",
    "    img = os.path.join('training',i,train_class[j])\n",
    "    \n",
    "    img = PIL.Image.open(img)\n",
    "    axs[count][j].title.set_text(i)\n",
    "    axs[count][j].imshow(img)  \n",
    "  count += 1\n",
    "\n",
    "fig.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 375
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 54573,
     "status": "ok",
     "timestamp": 1592518678793,
     "user": {
      "displayName": "Kukeshajanth Kodeswaran",
      "photoUrl": "",
      "userId": "09269573466384281285"
     },
     "user_tz": 240
    },
    "id": "BgmZEvwgIzqc",
    "outputId": "e2ca8004-6783-42d3-ab76-0303a4130d7b"
   },
   "outputs": [],
   "source": [
    "# check the number of images in each class in the training dataset\n",
    "\n",
    "No_images_per_class = []\n",
    "Class_name = []\n",
    "for i in os.listdir('./training'):\n",
    "  train_class = os.listdir(os.path.join('training',i))\n",
    "  No_images_per_class.append(len(train_class))\n",
    "  Class_name.append(i)\n",
    "  print('Number of images in {} = {} \\n'.format(i,len(train_class)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 368
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 54566,
     "status": "ok",
     "timestamp": 1592518678795,
     "user": {
      "displayName": "Kukeshajanth Kodeswaran",
      "photoUrl": "",
      "userId": "09269573466384281285"
     },
     "user_tz": 240
    },
    "id": "5Bimf3qJN0bk",
    "outputId": "4e91ebd0-5b43-4b5e-ba62-839303e8f234"
   },
   "outputs": [],
   "source": [
    "# visualize the number of images in each class in the training dataset\n",
    "\n",
    "fig = plt.figure(figsize=(10,5))\n",
    "plt.bar(Class_name, No_images_per_class,color = sns.color_palette(\"cubehelix\",len(Class_name)))\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6E8ADCzp3H8i"
   },
   "source": [
    "##MINI TASK:\n",
    "\n",
    "- CREATE SIMILAR KIND OF VISUALIZAION FOR VALIDATION SET BUT IT SHOULD SHOW ONLY 3 IMAGES PER CLASS FOR ANY 5 CLASSES\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TRCi25WyuZ-T"
   },
   "source": [
    "# TASK #4: PERFORM DATA AUGMENTATION AND CREATE DATA GENERATOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7phFxj7xuUP4"
   },
   "outputs": [],
   "source": [
    "# create run-time augmentation on training and test dataset\n",
    "# For training datagenerator,we add normalization ,shear angle, zooming range and horizontal flip\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "# For test datagenerator, we only normalize the data.\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 66
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 54439,
     "status": "ok",
     "timestamp": 1592528456126,
     "user": {
      "displayName": "Kukeshajanth Kodeswaran",
      "photoUrl": "",
      "userId": "09269573466384281285"
     },
     "user_tz": 240
    },
    "id": "0gD1o9WpyOwy",
    "outputId": "c1df2577-5669-49c9-cf09-886f8e43cb26"
   },
   "outputs": [],
   "source": [
    "# Creating datagenerator for training, validation and test dataset.\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        'training',\n",
    "        target_size=(256, 256),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        'validation',\n",
    "        target_size=(256, 256),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical')\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        'evaluation',\n",
    "        target_size=(256, 256),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MXIiUszS3p0J"
   },
   "source": [
    "##MINI TASK:\n",
    "\n",
    "- TRY ADDING MORE AUGMENTATION TO THE TRAINING DATA\n",
    "\n",
    "HINT: https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FfEKHbKJxPKo"
   },
   "source": [
    "# TASK #5: TRANSFER LEARNING INTUTION:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ser8TL4hx0d1"
   },
   "source": [
    "# TASK #6: BUILD DEEP LEARNING MODEL USING PRE-TRAINED INCEPTIONRESNETV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 75456,
     "status": "ok",
     "timestamp": 1592528477215,
     "user": {
      "displayName": "Kukeshajanth Kodeswaran",
      "photoUrl": "",
      "userId": "09269573466384281285"
     },
     "user_tz": 240
    },
    "id": "DuDXHzHwz3dR",
    "outputId": "b5d048ae-1493-44d2-e3f3-4a159f5af3d6"
   },
   "outputs": [],
   "source": [
    "# load the inception resnetv2 model\n",
    "# basemodel = MobileNet(weights = 'imagenet', include_top = False, input_tensor = Input(shape=(256,256,3)))\n",
    "basemodel = ResNet50(weights = 'imagenet', include_top = False, input_tensor = Input(shape=(256,256,3)))\n",
    "# basemodel = InceptionResNetV2(weights = 'imagenet', include_top = False, input_tensor = Input(shape=(256,256,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 75141,
     "status": "ok",
     "timestamp": 1592528477216,
     "user": {
      "displayName": "Kukeshajanth Kodeswaran",
      "photoUrl": "",
      "userId": "09269573466384281285"
     },
     "user_tz": 240
    },
    "id": "1HLFCO1H05C2",
    "outputId": "16b2d97a-e8b4-4f1c-e941-21319485ab2f"
   },
   "outputs": [],
   "source": [
    "# print the model summary\n",
    "basemodel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EN_NR37Z07Z-"
   },
   "outputs": [],
   "source": [
    "# Freeze the basemodel weights , so these weights won't change during training\n",
    "basemodel.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "utpCBuch5K5j"
   },
   "outputs": [],
   "source": [
    "# Add classifiction head to the model\n",
    "\n",
    "headmodel = basemodel.output\n",
    "headmodel = GlobalAveragePooling2D(name = 'global_average_pool')(headmodel)\n",
    "headmodel = Flatten(name= 'flatten')(headmodel)\n",
    "headmodel = Dense(256, activation = \"relu\", name = 'dense_1')(headmodel)\n",
    "headmodel = Dropout(0.3)(headmodel)\n",
    "headmodel = Dense(128, activation = \"relu\", name = 'dense_2')(headmodel)\n",
    "headmodel = Dropout(0.2)(headmodel)\n",
    "headmodel = Dense(11, activation = 'softmax', name = 'dense_3')(headmodel)\n",
    "\n",
    "model = Model(inputs = basemodel.input, outputs = headmodel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dcI-eaX3FI5p"
   },
   "source": [
    "##MINI TASK:\n",
    "\n",
    "- TRY USING A DIFFERENT PRE-TRAINED ARCHITECTURE LIKE VGG, RESNET AND TRAIN THE MODEL.COMPARE THEIR PERFORMANCE\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mv5gK4Yjztgt"
   },
   "source": [
    "# TASK #7: COMPILE AND TRAIN DEEP LEARNING MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L02vuv875Uv7"
   },
   "outputs": [],
   "source": [
    "# compile the model\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer= SGD(lr=.01, momentum=.9) , metrics= [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wNwcURek5YnQ"
   },
   "outputs": [],
   "source": [
    "# using early stopping to exit training if validation loss is not decreasing even after certain epochs (patience)\n",
    "earlystopping = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=20)\n",
    "\n",
    "# save the best model with lower validation loss\n",
    "checkpointer = ModelCheckpoint(filepath=\"weights.hdf5\", verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2351506,
     "status": "ok",
     "timestamp": 1592377329335,
     "user": {
      "displayName": "kodess kodess",
      "photoUrl": "",
      "userId": "01403956837925408838"
     },
     "user_tz": 240
    },
    "id": "AkFyneJU6Dot",
    "outputId": "de1eb054-9c10-4b8d-d688-3171de288704"
   },
   "outputs": [],
   "source": [
    "history = model.fit_generator(train_generator, steps_per_epoch= train_generator.n // 32, epochs = 5, validation_data= validation_generator, validation_steps= validation_generator.n // 32, callbacks=[checkpointer, earlystopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 619,
     "status": "ok",
     "timestamp": 1592378051582,
     "user": {
      "displayName": "kodess kodess",
      "photoUrl": "",
      "userId": "01403956837925408838"
     },
     "user_tz": 240
    },
    "id": "CXNYYqTwIJIG",
    "outputId": "3f1fd477-8a6c-42d5-c2cc-42617209a333"
   },
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train_loss','val_loss'], loc = 'upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BZcag9NBFgxU"
   },
   "source": [
    "##MINI TASK:\n",
    "\n",
    "- TRY USING DIFFERENT OPTIMIZER TO TRAIN THE MODEL .\n",
    "- CHANGE THE VALUE OF PATIENCE IN EARLY STOPPING.\n",
    "\n",
    "WHAT DID YOU INFER ?\n",
    "ANSWER:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5XsIk6XQz3fH"
   },
   "source": [
    "# TASK #8: FINE TUNE THE TRAINED MODEL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f8Vg55sU6N7s"
   },
   "outputs": [],
   "source": [
    "#unfreeze the weights in the base model, now these weights will be changed during training\n",
    "\n",
    "basemodel.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1510,
     "status": "ok",
     "timestamp": 1592528482988,
     "user": {
      "displayName": "Kukeshajanth Kodeswaran",
      "photoUrl": "",
      "userId": "09269573466384281285"
     },
     "user_tz": 240
    },
    "id": "RijFgtp_H3w2",
    "outputId": "a5efa093-85f0-437b-c2f6-427dbd4f4172"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sXb_P5YbI1IA"
   },
   "outputs": [],
   "source": [
    "#using early stopping to exit training if validation loss is not decreasing even after certain epochs (patience)\n",
    "earlystopping = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=20)\n",
    "\n",
    "#save the best model with lower validation loss\n",
    "checkpointer = ModelCheckpoint(filepath=\"weights_fine.hdf5\", verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 667
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2378062,
     "status": "ok",
     "timestamp": 1592380969955,
     "user": {
      "displayName": "kodess kodess",
      "photoUrl": "",
      "userId": "01403956837925408838"
     },
     "user_tz": 240
    },
    "id": "JTIVBL27H7qM",
    "outputId": "adeeb111-6071-46af-a12d-89b6c839c6fd"
   },
   "outputs": [],
   "source": [
    "#fine tune the model with very low learning rate\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer= SGD(lr=0.0001, momentum=.9) , metrics= [\"accuracy\"])\n",
    "history = model.fit(train_generator, steps_per_epoch= train_generator.n // 32, epochs = 10, validation_data= validation_generator, validation_steps= validation_generator.n // 32, callbacks=[checkpointer, earlystopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Bv0u2ZqmFdWn"
   },
   "outputs": [],
   "source": [
    "model.load_weights(\"weights_fine.hdf5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Vnj2kcG0Ksu1"
   },
   "source": [
    "##MINI TASK:\n",
    "\n",
    "-WHAT HAPPEND WHEN YOU FINE TUNE THE MODEL WITH HIGH LEARNING RATE. TRY IT AND WHAT DID YOU INFER\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "od4ORdp50W8O"
   },
   "source": [
    "# TASK #9: ASSESS THE PERFORMANCE OF THE TRAINED MODEL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 118
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 815370,
     "status": "ok",
     "timestamp": 1592381786043,
     "user": {
      "displayName": "kodess kodess",
      "photoUrl": "",
      "userId": "01403956837925408838"
     },
     "user_tz": 240
    },
    "id": "-ox5UpdcIe1L",
    "outputId": "ca6b59fa-96a5-45e7-db8c-780572a4b594"
   },
   "outputs": [],
   "source": [
    "#Evaluate the performance of the model\n",
    "evaluate = model.evaluate_generator(test_generator, steps = test_generator.n // 32, verbose =1)\n",
    "\n",
    "print('Accuracy Test : {}'.format(evaluate[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GmXWmLQPOGCc"
   },
   "outputs": [],
   "source": [
    "#assigning label names to the corresponding indexes\n",
    "labels = {0: 'Bread', 1: 'Dairy product', 2: 'Dessert', 3:'Egg', 4: 'Fried food', 5:'Meat',6:'Noodles-Pasta',7:'Rice', 8:'Seafood',9:'Soup',10: 'Vegetable-Fruit'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ja8K9HDUMvXN"
   },
   "outputs": [],
   "source": [
    "#loading images and their predictions \n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "import cv2\n",
    "\n",
    "prediction = []\n",
    "original = []\n",
    "image = []\n",
    "count = 0\n",
    "for i in os.listdir('./evaluation'):\n",
    "  for item in os.listdir(os.path.join('./evaluation',i)):\n",
    "    #code to open the image\n",
    "    img= PIL.Image.open(os.path.join('./evaluation',i,item))\n",
    "    #resizing the image to (256,256)\n",
    "    img = img.resize((256,256))\n",
    "    #appending image to the image list\n",
    "    image.append(img)\n",
    "    #converting image to array\n",
    "    img = np.asarray(img, dtype= np.float32)\n",
    "    #normalizing the image\n",
    "    img = img / 255\n",
    "    #reshaping the image in to a 4D array\n",
    "    img = img.reshape(-1,256,256,3)\n",
    "    #making prediction of the model\n",
    "    predict = model.predict(img)\n",
    "    #getting the index corresponding to the highest value in the prediction\n",
    "    predict = np.argmax(predict)\n",
    "    #appending the predicted class to the list\n",
    "    prediction.append(labels[predict])\n",
    "    #appending original class to the list\n",
    "    original.append(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 766,
     "status": "ok",
     "timestamp": 1592414497885,
     "user": {
      "displayName": "Kukeshajanth Kodeswaran",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj_hF0QlKjkAZvh3_nIU1Fj3LuIyLifAN3KKIdI7A=s64",
      "userId": "01021579274124875186"
     },
     "user_tz": 240
    },
    "id": "AJF0bF1xSE10",
    "outputId": "d2a905f0-8074-4fbe-c697-30d7d9cf2c15"
   },
   "outputs": [],
   "source": [
    "#Getting the test accuracy \n",
    "score = accuracy_score(original,prediction)\n",
    "print(\"Test Accuracy : {}\".format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2063864,
     "status": "ok",
     "timestamp": 1592520688265,
     "user": {
      "displayName": "Kukeshajanth Kodeswaran",
      "photoUrl": "",
      "userId": "09269573466384281285"
     },
     "user_tz": 240
    },
    "id": "uIi_GI-oSG1a",
    "outputId": "bd66d579-444f-49ef-ecad-861dc232fbeb"
   },
   "outputs": [],
   "source": [
    "#visualizing the results\n",
    "import random\n",
    "fig=plt.figure(figsize = (100,100))\n",
    "for i in range(20):\n",
    "    j = random.randint(0,len(image))\n",
    "    fig.add_subplot(20,1,i+1)\n",
    "    plt.xlabel(\"Prediction -\" + prediction[j] +\"   Original -\" + original[j])\n",
    "    plt.imshow(image[j])\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 310
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 763,
     "status": "ok",
     "timestamp": 1592414874023,
     "user": {
      "displayName": "Kukeshajanth Kodeswaran",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj_hF0QlKjkAZvh3_nIU1Fj3LuIyLifAN3KKIdI7A=s64",
      "userId": "01021579274124875186"
     },
     "user_tz": 240
    },
    "id": "1XbmWMQcSM0b",
    "outputId": "9cc30eae-4189-4f9c-edca-3b94383c7a66"
   },
   "outputs": [],
   "source": [
    "#classiication report\n",
    "print(classification_report(np.asarray(original), np.asarray(prediction)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1668,
     "status": "ok",
     "timestamp": 1592414937283,
     "user": {
      "displayName": "Kukeshajanth Kodeswaran",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj_hF0QlKjkAZvh3_nIU1Fj3LuIyLifAN3KKIdI7A=s64",
      "userId": "01021579274124875186"
     },
     "user_tz": 240
    },
    "id": "HaXGkGP8OO98",
    "outputId": "6533a6f2-5ce8-485c-9992-84a479dff3d2"
   },
   "outputs": [],
   "source": [
    "#plotting confusion matrix\n",
    "\n",
    "plt.figure(figsize=(20,20))\n",
    "cm = confusion_matrix(np.asarray(original), np.asarray(prediction))\n",
    "ax = plt.subplot()\n",
    "sns.heatmap(cm, annot = True, ax = ax)\n",
    "\n",
    "ax.set_xlabel('Predicted')\n",
    "ax.set_ylabel('Original')\n",
    "ax.set_title('Confusion_matrix')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9L3EBf_bLEeV"
   },
   "source": [
    "##MINI TASK:\n",
    "\n",
    "- WHY IS THE MODEL PERFORMING POORLY ON DAIRY PRODUCTS?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XkuhUAIt2tfQ"
   },
   "source": [
    "# TASK #10: VISUALIZING ACTIVATION MAPS THROUGH GRAD-CAM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_nnwOS5PZS8D"
   },
   "outputs": [],
   "source": [
    "def grad_cam(img):\n",
    "\n",
    "  #Covert the image to array of type float32\n",
    "  img = np.asarray(img, dtype= np.float32)\n",
    "\n",
    "  #Reshape the image from (256,256,3) to (1,256,256,3)\n",
    "  img = img.reshape(-1,256,256,3)\n",
    "  img_scaled = img / 255\n",
    "\n",
    "  #Name of the layers we added to the base_model, you can find this in the model summaty\n",
    "  #Every-time you run the model, check the summary, as the name would change or to avoid it \n",
    "  #you can add name to each layer\n",
    "  classification_layers = [\"global_average_pool\",\"dense_1\",\"dense_2\",\"dense_3\"]\n",
    "\n",
    "  #Last convolutional layer in the base mdel, this woun't change as name has been already assigned to it.\n",
    "  final_conv = model.get_layer(\"conv_7b\")\n",
    "\n",
    "  #Create a model with original model input as input and the last conv_layer as the output\n",
    "  final_conv_model = keras.Model(model.inputs, final_conv.output)\n",
    "\n",
    "  #Then,we create the input for classification layer, which is the output of last conv layer\n",
    "  #In our case, output produced by the conv layer is of the shape (1,6,6,1536) \n",
    "  #Since, the classification input needs the features as input, we ignore the batch dimension\n",
    "\n",
    "  classification_input = keras.Input(shape=final_conv.output.shape[1:])\n",
    "\n",
    "  # We iterate through the classification layers, to get the final layer and then, append \n",
    "  #the layer as the output layer to the classification model.\n",
    "  temp = classification_input\n",
    "  for layer in classification_layers:\n",
    "      temp = model.get_layer(layer)(temp)\n",
    "  classification_model = keras.Model(classification_input, temp)\n",
    "\n",
    "\n",
    "  #We use gradient tape to monitor the 'final_conv_output' to retrive the gradients\n",
    "  #corresponding to the predicted class\n",
    "  with tf.GradientTape() as tape:\n",
    "      # Pass the image through the base model and get the feature map \n",
    "      final_conv_output = final_conv_model(img_scaled)\n",
    "\n",
    "      #Assign gradient tape to monitor the conv_output\n",
    "      tape.watch(final_conv_output)\n",
    "      \n",
    "      #Pass the feature map through the classification model and use argmax to get the \n",
    "      #index of the predicted class and then use the index to get the value produced by final\n",
    "      #layer for that class\n",
    "      prediction = classification_model(final_conv_output)\n",
    "      predicted_class = tf.argmax(prediction[0])\n",
    "      predicted_class_value = prediction[:, predicted_class]\n",
    "\n",
    "  #Get the gradient corresponding to the predicted class based on feature map.\n",
    "  #which is of shape (1,6,6,1536)\n",
    "  gradient = tape.gradient(predicted_class_value, final_conv_output)\n",
    "\n",
    "  #Since we need the filter values (1536), we reduce the other dimensions, \n",
    "  #hich would result in a shape of (1536,)\n",
    "  gradient_channels = tf.reduce_mean(gradient, axis=(0, 1, 2))\n",
    "\n",
    "  #We then convert the feature map produced by last conv layer(1,6,6,1536) to (6,6,1536)\n",
    "\n",
    "  final_conv_output = final_conv_output.numpy()[0]\n",
    "\n",
    "  gradient_channels = gradient_channels.numpy()\n",
    "\n",
    "  #We multiply the filters in the feature map produced by final conv layer by the \n",
    "  #filter values that are used to get the predicted class. By doing this we inrease the\n",
    "  #value of areas that helped in making the prediction and lower the vlaue of areas, that \n",
    "  #did not contribute towards the final prediction\n",
    "  for i in range(gradient_channels.shape[-1]):\n",
    "      final_conv_output[:, :, i] *= gradient_channels[i]\n",
    "\n",
    "  #We take the mean accross the channels to get the feature map\n",
    "  heatmap = np.mean(final_conv_output, axis=-1)\n",
    "\n",
    "  #Normalizing the heat map between 0 and 1, to visualize it\n",
    "  heatmap_normalized = np.maximum(heatmap, 0) / np.max(heatmap)\n",
    "\n",
    "  # Rescaling and converting the type to int\n",
    "  heatmap = np.uint8(255 * heatmap_normalized )\n",
    "\n",
    "  # Create the colormap\n",
    "  color_map = plt.cm.get_cmap('jet')\n",
    "\n",
    "  # get only the rb features from the heatmap\n",
    "  color_map = color_map(np.arange(256))[:, :3]\n",
    "  heatmap = color_map[heatmap]\n",
    "\n",
    "  #convert the array to image, resize the image and then convert to array\n",
    "  heatmap = keras.preprocessing.image.array_to_img(heatmap)\n",
    "  heatmap = heatmap.resize((256, 256))\n",
    "  heatmap = np.asarray(heatmap, dtype = np.float32)\n",
    "\n",
    "  # Add the heatmap o top of the original image\n",
    "  final_img = heatmap * 0.8 + img[0]\n",
    "  final_img = keras.preprocessing.image.array_to_img(final_img)\n",
    "\n",
    "  return final_img, heatmap_normalized\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 15307,
     "status": "ok",
     "timestamp": 1592531611537,
     "user": {
      "displayName": "Kukeshajanth Kodeswaran",
      "photoUrl": "",
      "userId": "09269573466384281285"
     },
     "user_tz": 240
    },
    "id": "F1CFXeOvd0Fe",
    "outputId": "6dfb7ea2-d6ad-43d0-c470-7510bcd434db"
   },
   "outputs": [],
   "source": [
    "#Visualize the images in the dataset\n",
    "import random\n",
    "fig, axs = plt.subplots(11,3, figsize=(32,32))\n",
    "count = 0\n",
    "for _ in range(11):\n",
    "  i = random.randint(0,len(image))\n",
    "  gradcam, heatmap = grad_cam(image[i])\n",
    "  axs[count][0].title.set_text(\"Original -\" + original[i])\n",
    "  axs[count][0].imshow(image[i])\n",
    "  axs[count][1].title.set_text(\"Prediction -\" + prediction[i]) \n",
    "  axs[count][1].matshow(heatmap)\n",
    "  axs[count][2].title.set_text(\"Heatmap\") \n",
    "  axs[count][2].imshow(gradcam)  \n",
    "  count += 1\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OEj_LTpWLtGK"
   },
   "source": [
    "##MINI TASK:\n",
    "\n",
    "- SINCE THE MODEL IS PERFORMING POORLY ON DAIRY PRODUCTS, USE GRAD-CAM TO SEE, WHERE THE MODEL IS FOCUSING WHILE MAKING PREDICTIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0KCob34r3CTG"
   },
   "source": [
    "# CONGRATULATIONS ON FINISHING THE PROJECT!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ATs22abRdDiE"
   },
   "source": [
    "##MINI TASK 1:\n",
    "\n",
    "- CREATE SIMILAR KIND OF VISUALIZAION FOR VALIDATION SET BUT IT SHOULD SHOW ONLY 3 IMAGES PER CLASS FOR ANY 5 CLASSES\n",
    "\n",
    "#Visualize the images in the dataset\n",
    "```python\n",
    "fig, axs = plt.subplots(5,3, figsize=(32,32))\n",
    "count = 0\n",
    "for i in os.listdir('./training'):\n",
    "  # get the list of images in the particualr class\n",
    "  train_class = os.listdir(os.path.join('training',i))\n",
    "  #plot 5 images per class\n",
    "  for j in range(3):\n",
    "    img = os.path.join('training',i,train_class[j])\n",
    "    img = PIL.Image.open(img)\n",
    "    axs[count][j].title.set_text(i)\n",
    "    axs[count][j].imshow(img)  \n",
    "  count += 1\n",
    "\n",
    "fig.tight_layout()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GqBsTcxBd1PU"
   },
   "source": [
    "##MINI TASK 2:\n",
    "\n",
    "- TRY ADDING MORE AUGMENTATION TO THE TRAINING DATA\n",
    "\n",
    "HINT: https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator\n",
    "\n",
    "\n",
    "  \n",
    "\n",
    "```python\n",
    "\n",
    "tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "      featurewise_center=False,\n",
    "      samplewise_center=False,\n",
    "      featurewise_std_normalization=False,\n",
    "      samplewise_std_normalization=False,\n",
    "      zca_whitening=False,\n",
    "      zca_epsilon=1e-06,\n",
    "      rotation_range=0,\n",
    "      width_shift_range=0.0,\n",
    "      height_shift_range=0.0,\n",
    "      brightness_range=None,\n",
    "      shear_range=0.0,\n",
    "      zoom_range=0.0,\n",
    "      channel_shift_range=0.0,\n",
    "      fill_mode=\"nearest\",\n",
    "      cval=0.0,\n",
    "      horizontal_flip=False,\n",
    "      vertical_flip=False,\n",
    "      rescale=None,\n",
    "      preprocessing_function=None,\n",
    "      data_format=None,\n",
    "      validation_split=0.0,\n",
    "      dtype=None)\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "okznfyITeaVA"
   },
   "source": [
    "##MINI TASK 3:\n",
    "\n",
    "- TRY USING A DIFFERENT PRE-TRAINED ARCHITECTURE LIKE VGG, RESNET AND TRAIN THE MODEL.COMPARE THEIR PERFORMANCE\n",
    "\n",
    "\n",
    "\n",
    "```python\n",
    "\n",
    "#load the inception resnetv2 model\n",
    "\n",
    "basemodel = ResNet50(weights = 'imagenet', include_top = False, input_tensor = Input(shape=(256,256,3)))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bUfhf0jRe6aq"
   },
   "source": [
    "##MINI TASK 4:\n",
    "\n",
    "- TRY USING DIFFERENT OPTIMIZER TO TRAIN THE MODEL .\n",
    "- CHANGE THE VALUE OF PATIENCE IN EARLY STOPPING.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "- Try optimizers like adam, ndam\n",
    "- Change the value of patience to 25 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FXiBS6nAfha4"
   },
   "source": [
    "##MINI TASK 5:\n",
    "\n",
    "WHAT HAPPEND WHEN YOU FINE TUNE THE MODEL WITH HIGH LEARNING RATE. TRY IT AND WHAT DID YOU INFER\n",
    "\n",
    "(Increase the learning rate to 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6RIusY7Ce8C7"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Copy of Food11.ipynb..",
   "provenance": [
    {
     "file_id": "1rFmnEI1hvJ4UZphYSfoZiTaw7cGuj2iA",
     "timestamp": 1592631060630
    }
   ],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
